import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import os
from tensorflow.keras import layers, models
from sklearn.utils.class_weight import compute_class_weight

DATA_DIR = "data"
MODEL_PATH = "model/my_sound_model.h5"

yamnet_model_handle = "https://tfhub.dev/google/yamnet/1"
yamnet_model = hub.load(yamnet_model_handle)

def load_wav_16k_mono(filename):
    file_contents = tf.io.read_file(filename)
    audio, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)
    audio = tf.squeeze(audio, axis=-1)
    
    # Convert to 16kHz if needed
    sample_rate = tf.cast(sample_rate, tf.float32)
    if tf.not_equal(sample_rate, 16000.0):
        # Calculate target length for 16kHz
        current_length = tf.cast(tf.shape(audio)[0], tf.float32)
        target_length = tf.cast(current_length * 16000.0 / sample_rate, tf.int32)
        
        # Resample using signal processing
        indices = tf.cast(tf.linspace(0.0, current_length - 1, target_length), tf.int32)
        audio = tf.gather(audio, indices)
    
    return audio

def extract_embedding(filename):
    audio = load_wav_16k_mono(filename)
    scores, embeddings, spectrogram = yamnet_model(audio)
    embedding = tf.reduce_mean(embeddings, axis=0)
    return embedding

def augment_audio_embedding(embedding, num_augmentations=5):
    """–°–æ–∑–¥–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    augmented = [embedding]
    
    for _ in range(num_augmentations):
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —à—É–º
        noise = tf.random.normal(shape=embedding.shape, mean=0.0, stddev=0.001)
        augmented_emb = embedding + noise
        augmented.append(augmented_emb)
    
    return augmented

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
X, y = [], []
class_names = sorted(os.listdir(DATA_DIR))

# –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
all_embeddings = {class_name: [] for class_name in class_names}

for label_idx, class_name in enumerate(class_names):
    folder = os.path.join(DATA_DIR, class_name)
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º {class_name}...")
    
    for file in os.listdir(folder):
        if file.endswith(".wav"):
            path = os.path.join(folder, file)
            emb = extract_embedding(path)
            all_embeddings[class_name].append(emb.numpy())

# –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
neg_count = len(all_embeddings['negative'])
pos_count = len(all_embeddings['positive'])

print(f"üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
print(f"  negative: {neg_count} —Ñ–∞–π–ª–æ–≤")
print(f"  positive: {pos_count} —Ñ–∞–π–ª–æ–≤")

# –ê—É–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º positive –∫–ª–∞—Å—Å –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
target_count = min(neg_count, 500)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
augmentation_factor = target_count // pos_count

print(f"üîÑ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è positive –∫–ª–∞—Å—Å: {augmentation_factor}x")

# –î–æ–±–∞–≤–ª—è–µ–º negative –ø—Ä–∏–º–µ—Ä—ã (–±–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É –µ—Å–ª–∏ –∏—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ)
negative_embeddings = all_embeddings['negative']
if len(negative_embeddings) > target_count:
    indices = np.random.choice(len(negative_embeddings), target_count, replace=False)
    negative_embeddings = [negative_embeddings[i] for i in indices]

for emb in negative_embeddings:
    X.append(emb)
    y.append(0)

# –î–æ–±–∞–≤–ª—è–µ–º positive –ø—Ä–∏–º–µ—Ä—ã —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π
for emb in all_embeddings['positive']:
    emb_tensor = tf.constant(emb)
    augmented_embs = augment_audio_embedding(emb_tensor, augmentation_factor - 1)
    
    for aug_emb in augmented_embs:
        X.append(aug_emb.numpy())
        y.append(1)

X = np.array(X)
y = np.array(y)

# –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
indices = np.random.permutation(len(X))
X = X[indices]
y = y[indices]

print(f"üìä –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
print(f"  negative: {np.sum(y == 0)} —Ñ–∞–π–ª–æ–≤")
print(f"  positive: {np.sum(y == 1)} —Ñ–∞–π–ª–æ–≤")

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
model = models.Sequential([
    layers.Input(shape=(1024,)),
    layers.Dense(512, activation="relu"),
    layers.BatchNormalization(),
    layers.Dropout(0.4),
    layers.Dense(256, activation="relu"),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.2),
    layers.Dense(len(class_names), activation="softmax")
])

# –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Å –º–µ–Ω—å—à–∏–º learning rate
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), 
    loss="sparse_categorical_crossentropy", 
    metrics=["accuracy"]
)

# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
history = model.fit(
    X, y, 
    epochs=100, 
    batch_size=32, 
    validation_split=0.2,
    verbose=1
)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
os.makedirs("model", exist_ok=True)
model.save(MODEL_PATH)

print(f"‚úÖ –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")