import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import sounddevice as sd
import time
from collections import deque
import threading
import sys

# –ü—É—Ç–∏
MODEL_PATH = "model/my_sound_model.h5"
yamnet_model = hub.load("https://tfhub.dev/google/yamnet/1")
classifier = tf.keras.models.load_model(MODEL_PATH)
class_names = ["negative", "positive"]

SAMPLE_RATE = 16000
BLOCK_DURATION = 1.0
BLOCK_SIZE = int(SAMPLE_RATE * BLOCK_DURATION)
MIN_CONFIDENCE = 0.8  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –≤—ã–≤–æ–¥–∞
SMOOTH_WINDOW = 3     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
RMS_THRESHOLD = 0.01  # –ü–æ—Ä–æ–≥ —à—É–º–∞

# –ë—É—Ñ–µ—Ä—ã –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
prediction_buffer = deque(maxlen=SMOOTH_WINDOW)
volume_buffer = deque(maxlen=10)  # –î–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
last_prediction = None
last_time = 0
current_volume = 0.0
is_running = True

def extract_embedding_from_audio(audio):
    scores, embeddings, spectrogram = yamnet_model(audio)
    embedding = tf.reduce_mean(embeddings, axis=0)
    return embedding

def smooth_predictions(new_prediction):
    """–°–≥–ª–∞–∂–∏–≤–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π"""
    prediction_buffer.append(new_prediction)
    
    if len(prediction_buffer) < SMOOTH_WINDOW:
        return None
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
    negative_count = sum(1 for p in prediction_buffer if p == 0)
    positive_count = sum(1 for p in prediction_buffer if p == 1)
    
    return 0 if negative_count >= positive_count else 1

def create_volume_bar(volume, max_width=40):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—É—é –ø–æ–ª–æ—Å–∫—É –≥—Ä–æ–º–∫–æ—Å—Ç–∏"""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞)
    if volume <= 0:
        normalized = 0
    else:
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        normalized = min(1.0, np.log10(volume * 1000 + 1) / 3)
    
    filled_width = int(normalized * max_width)
    bar = "‚ñà" * filled_width + "‚ñë" * (max_width - filled_width)
    
    # –¶–≤–µ—Ç–æ–≤–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞
    if volume < RMS_THRESHOLD:
        color = "üîá"  # –¢–∏—Ö–æ
    elif volume < 0.05:
        color = "üîâ"  # –°—Ä–µ–¥–Ω–µ
    else:
        color = "üîä"  # –ì—Ä–æ–º–∫–æ
    
    return f"{color} |{bar}| {volume:.3f}"

def volume_display_thread():
    """–û—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –≤ real-time"""
    while is_running:
        if volume_buffer:
            avg_volume = np.mean(list(volume_buffer))
            volume_bar = create_volume_bar(avg_volume)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ –≤—ã–≤–æ–¥–∏–º –≥—Ä–æ–º–∫–æ—Å—Ç—å
            sys.stdout.write(f"\r{volume_bar}")
            sys.stdout.flush()
        
        time.sleep(0.1)  # –û–±–Ω–æ–≤–ª—è–µ–º 10 —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É

def audio_callback(indata, frames, time_info, status):
    global last_prediction, last_time, current_volume
    
    if status:
        print(f"\n‚ö†Ô∏è Audio status: {status}")
    
    try:
        # –í—ã—á–∏—Å–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (RMS)
        mono = np.mean(indata, axis=1).astype(np.float32)
        rms = np.sqrt(np.mean(mono**2))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        volume_buffer.append(rms)
        current_volume = rms
        
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —Ç–∏—Ö–∏–µ –∑–≤—É–∫–∏ (—Ñ–æ–Ω–æ–≤—ã–π —à—É–º)
        if rms < RMS_THRESHOLD:
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
        emb = extract_embedding_from_audio(mono)
        pred = classifier.predict(np.expand_dims(emb, axis=0), verbose=0)[0]
        label_idx = np.argmax(pred)
        confidence = pred[label_idx]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
        smoothed_prediction = smooth_predictions(label_idx)
        
        # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        current_time = time.time()
        if (smoothed_prediction is not None and 
            confidence > MIN_CONFIDENCE and 
            smoothed_prediction != last_prediction and
            current_time - last_time > 1.0):  # –ú–∏–Ω–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞ –º–µ–∂–¥—É –≤—ã–≤–æ–¥–∞–º–∏
            
            label = class_names[smoothed_prediction]
            # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –∏ –≤—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            sys.stdout.write("\r" + " " * 60 + "\r")  # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É
            print(f"üéß {label.upper()} (conf: {confidence:.2f}, vol: {rms:.3f})")
            last_prediction = smoothed_prediction
            last_time = current_time
            
    except Exception as e:
        print(f"\n‚ùå Error in audio callback: {e}")

print("üéôÔ∏è –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –≥—Ä–æ–º–∫–æ—Å—Ç–∏")
print(f"üìä –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {MIN_CONFIDENCE}")
print(f"üîÑ –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ: {SMOOTH_WINDOW} –∫–∞–¥—Ä–æ–≤")
print(f"üéöÔ∏è –ü–æ—Ä–æ–≥ —à—É–º–∞: {RMS_THRESHOLD}")
print("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –≤ real-time")
print("(Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)\n")

# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
volume_thread = threading.Thread(target=volume_display_thread, daemon=True)
volume_thread.start()

with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, callback=audio_callback, blocksize=BLOCK_SIZE):
    try:
        while True:
            time.sleep(0.1)
    except KeyboardInterrupt:
        is_running = False
        sys.stdout.write("\r" + " " * 60 + "\r")  # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É
        print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞")
