#!/usr/bin/env python3
"""
üéØ –ü–æ–ª–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º
–ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç AI –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∑–≤—É–∫–æ–≤ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
"""

import numpy as np
import sounddevice as sd
import tensorflow as tf
import tensorflow_hub as hub
import json
import time
import math
from datetime import datetime
from collections import deque
import scipy.signal

class FullDistanceDetector:
    def __init__(self, calibration_file='distance_calibration.json'):
        print("üéØ === –ü–û–õ–ù–´–ô –î–ï–¢–ï–ö–¢–û–† –° –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ï–ô ===")
        print("ü§ñ AI –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è + –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")
        print("üìè –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∑–≤—É–∫–∞")
        print("=" * 50)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.SAMPLE_RATE = 16000
        self.WINDOW_SIZE = 0.975  # –°–µ–∫—É–Ω–¥—ã
        self.CHUNK_SIZE = int(self.SAMPLE_RATE * self.WINDOW_SIZE)
        self.CONFIDENCE_THRESHOLD = 0.8
        self.NOISE_THRESHOLD = 0.001
        self.MIN_VOLUME = 0.005
        self.SMOOTHING_FRAMES = 3
        
        # –ë—É—Ñ–µ—Ä—ã –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.prediction_buffer = deque(maxlen=self.SMOOTHING_FRAMES)
        self.volume_buffer = deque(maxlen=10)
        self.distance_buffer = deque(maxlen=5)
        self.db_buffer = deque(maxlen=3)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.load_calibration_data(calibration_file)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        self.load_model()
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        self.calibrate_microphone()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.running = False
        self.last_detection = None
        self.environment_type = "indoor"
        self.detections_count = 0
        
    def load_calibration_data(self, filename):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.calibration = json.load(f)
            print(f"‚úÖ –ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {filename}")
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
            self.distance_table = []
            mapping = self.calibration['calibration_data']['distance_db_mapping']
            for distance_str, data in mapping.items():
                distance = float(distance_str)
                db = data['db']
                self.distance_table.append((db, distance, data['description']))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –¥–ë
            self.distance_table.sort(key=lambda x: x[0], reverse=True)
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
            self.create_default_calibration()
    
    def create_default_calibration(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        self.distance_table = [
            (70, 0.3, "–û—á–µ–Ω—å –±–ª–∏–∑–∫–æ"),
            (65, 0.5, "–ë–ª–∏–∑–∫–æ"),
            (60, 1.0, "–†—è–¥–æ–º"),
            (55, 1.5, "–ë–ª–∏–∑–∫–æ"),
            (50, 2.0, "–°—Ä–µ–¥–Ω–µ"),
            (45, 3.0, "–î–∞–ª–µ–∫–æ"),
            (40, 4.0, "–î–∞–ª–µ–∫–æ"),
            (35, 5.0, "–û—á–µ–Ω—å –¥–∞–ª–µ–∫–æ"),
            (30, 7.0, "–ö—Ä–∞–π–Ω–µ –¥–∞–ª–µ–∫–æ"),
            (25, 10.0, "–ù–∞ –ø—Ä–µ–¥–µ–ª–µ")
        ]
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ AI –º–æ–¥–µ–ª–∏"""
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ YAMNet...")
        self.yamnet_model = hub.load('https://www.kaggle.com/models/google/yamnet/frameworks/TensorFlow2/variations/yamnet/versions/1')
        print("‚úÖ YAMNet –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å .h5 —Ñ–∞–π–ª
            self.classifier = tf.keras.models.load_model('model/my_sound_model.h5', compile=False)
            print("‚úÖ H5 –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ H5: {e}")
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å
                self.classifier = tf.keras.models.load_model('model', compile=False)
                print("‚úÖ SavedModel –∑–∞–≥—Ä—É–∂–µ–Ω")
            except Exception as e2:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e2}")
                print("ü§ñ –†–∞–±–æ—Ç–∞–µ–º –±–µ–∑ AI –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                self.classifier = None
    
    def calibrate_microphone(self):
        """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        print("üéôÔ∏è –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...")
        print("üîá –°–æ–∑–¥–∞–π—Ç–µ —Ç–∏—à–∏–Ω—É –Ω–∞ 3 —Å–µ–∫—É–Ω–¥—ã...")
        
        # –ó–∞–ø–∏—Å—å —Ç–∏—à–∏–Ω—ã
        silence_samples = []
        for i in range(3):
            print(f"   {3-i}...")
            time.sleep(1)
            audio = sd.rec(int(self.SAMPLE_RATE * 0.5), samplerate=self.SAMPLE_RATE, channels=1, dtype=np.float32)
            sd.wait()
            silence_samples.append(np.abs(audio.flatten()).mean())
        
        self.noise_floor = max(np.mean(silence_samples), 1e-8)
        print(f"‚úÖ –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞: {self.noise_floor:.6f}")
    
    def calculate_decibels(self, audio_data):
        """–†–∞—Å—á–µ—Ç –¥–µ—Ü–∏–±–µ–ª –∏–∑ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"""
        # RMS (Root Mean Square)
        rms = np.sqrt(np.mean(audio_data**2))
        
        # –ò–∑–±–µ–≥–∞–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º –æ—Ç –Ω—É–ª—è
        if rms < self.noise_floor:
            rms = self.noise_floor
            
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –¥–µ—Ü–∏–±–µ–ª—ã
        db = 20 * np.log10(rms / self.noise_floor)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è)
        db = max(0, db + 60)  # –ë–∞–∑–æ–≤–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
        
        return db
    
    def interpolate_distance(self, db_level):
        """–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ë"""
        # –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Ç–∞–±–ª–∏—Ü–µ
        for i, (table_db, table_dist, desc) in enumerate(self.distance_table):
            if db_level >= table_db:
                if i == 0:
                    return table_dist, desc
                
                # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏
                prev_db, prev_dist, prev_desc = self.distance_table[i-1]
                
                # –ü—Ä–æ–ø–æ—Ä—Ü–∏—è –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏
                ratio = (db_level - table_db) / (prev_db - table_db)
                distance = table_dist + ratio * (prev_dist - table_dist)
                
                return distance, f"–ú–µ–∂–¥—É {prev_desc.lower()} –∏ {desc.lower()}"
        
        # –ï—Å–ª–∏ –¥–ë –º–µ–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –≤ —Ç–∞–±–ª–∏—Ü–µ
        return self.distance_table[-1][1], self.distance_table[-1][2]
    
    def classify_audio(self, audio_data):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é AI"""
        if self.classifier is None:
            return "unknown", 0.5, "üîä"
        
        try:
            # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –¥–ª—è YAMNet
            resampled_audio = scipy.signal.resample(audio_data, self.CHUNK_SIZE)
            resampled_audio = np.float32(resampled_audio)
            
            # YAMNet —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            scores, embeddings, spectrogram = self.yamnet_model(resampled_audio)
            mean_embedding = np.mean(embeddings.numpy(), axis=0)
            mean_embedding = np.expand_dims(mean_embedding, axis=0)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = self.classifier.predict(mean_embedding, verbose=0)
            confidence = float(np.max(prediction))
            predicted_class = "positive" if prediction[0][1] > prediction[0][0] else "negative"
            
            # –ò–∫–æ–Ω–∫–∞ –∫–ª–∞—Å—Å–∞
            class_icon = "üü¢" if predicted_class == "positive" else "üî¥"
            
            return predicted_class, confidence, class_icon
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return "error", 0.0, "‚ùå"
    
    def smooth_values(self, db_level, distance):
        """–°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–Ω–∏–π"""
        self.db_buffer.append(db_level)
        self.distance_buffer.append(distance)
        
        if len(self.db_buffer) >= 3:
            smoothed_db = np.mean(list(self.db_buffer))
            smoothed_distance = np.median(list(self.distance_buffer))
            return smoothed_db, smoothed_distance
        
        return db_level, distance
    
    def determine_sound_type(self, audio_data):
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–≤—É–∫–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–∞–º"""
        # FFT –∞–Ω–∞–ª–∏–∑
        fft = np.fft.fft(audio_data)
        freqs = np.fft.fftfreq(len(fft), 1/self.SAMPLE_RATE)
        magnitude = np.abs(fft[:len(fft)//2])
        
        # –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã
        low_end = int(300 * len(magnitude) / (self.SAMPLE_RATE/2))
        mid_end = int(2000 * len(magnitude) / (self.SAMPLE_RATE/2))
        
        low_energy = np.mean(magnitude[10:low_end])
        mid_energy = np.mean(magnitude[low_end:mid_end])
        high_energy = np.mean(magnitude[mid_end:])
        
        total = low_energy + mid_energy + high_energy
        if total < 1e-6:
            return "—Ç–∏—à–∏–Ω–∞", "üîá"
        
        low_ratio = low_energy / total
        mid_ratio = mid_energy / total
        
        if mid_ratio > 0.6:
            return "—Ä–µ—á—å", "üó£Ô∏è"
        elif low_ratio > 0.5:
            return "–±–∞—Å", "ü•Å"
        else:
            return "—Å–º–µ—à–∞–Ω–Ω—ã–π", "üéµ"
    
    def format_distance(self, distance):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è"""
        if distance < 1.0:
            return f"{distance*100:.0f}—Å–º"
        elif distance < 10.0:
            return f"{distance:.1f}–º"
        else:
            return f"{distance:.0f}–º"
    
    def get_distance_icon(self, distance):
        """–ò–∫–æ–Ω–∫–∞ –¥–ª—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è"""
        if distance < 0.5:
            return "üî•"  # –û—á–µ–Ω—å –±–ª–∏–∑–∫–æ
        elif distance < 1.5:
            return "üìç"  # –ë–ª–∏–∑–∫–æ
        elif distance < 3.0:
            return "üìå"  # –°—Ä–µ–¥–Ω–µ
        elif distance < 5.0:
            return "üì°"  # –î–∞–ª–µ–∫–æ
        else:
            return "üå´Ô∏è"  # –û—á–µ–Ω—å –¥–∞–ª–µ–∫–æ
    
    def create_progress_bars(self, volume, distance, confidence=None):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        # –ì—Ä–æ–º–∫–æ—Å—Ç—å
        vol_bar_len = 25
        vol_filled = int((min(volume, 0.1) / 0.1) * vol_bar_len)
        vol_bar = f"üîä |{'‚ñà' * vol_filled}{'‚ñë' * (vol_bar_len - vol_filled)}| {volume:.3f}"
        
        # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ
        dist_bar_len = 30
        dist_pos = int((min(distance, 10) / 10) * dist_bar_len)
        dist_bar = f"üìè |{'‚ñë' * dist_pos}‚óè{'‚ñë' * (dist_bar_len - dist_pos)}| {self.format_distance(distance)}"
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–µ—Å–ª–∏ –µ—Å—Ç—å)
        conf_bar = ""
        if confidence is not None:
            conf_bar_len = 20
            conf_filled = int(confidence * conf_bar_len)
            conf_bar = f"üéØ |{'‚ñà' * conf_filled}{'‚ñë' * (conf_bar_len - conf_filled)}| {confidence:.2f}"
        
        return vol_bar, dist_bar, conf_bar
    
    def audio_callback(self, indata, frames, time, status):
        """Callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ"""
        if status:
            print(f"‚ö†Ô∏è –°—Ç–∞—Ç—É—Å –∞—É–¥–∏–æ: {status}")
        
        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        audio_data = indata[:, 0].copy()
        
        # –ò–∑–º–µ—Ä—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å
        volume = np.abs(audio_data).mean()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–∏—à–∏–Ω—É
        if volume < self.MIN_VOLUME:
            return
            
        try:
            # –†–∞—Å—á–µ—Ç –¥–µ—Ü–∏–±–µ–ª
            db_level = self.calculate_decibels(audio_data)
            
            # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            distance, description = self.interpolate_distance(db_level)
            
            # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
            smoothed_db, smoothed_distance = self.smooth_values(db_level, distance)
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–≤—É–∫–∞
            predicted_class, confidence, class_icon = self.classify_audio(audio_data)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–≤—É–∫–∞
            sound_type, sound_icon = self.determine_sound_type(audio_data)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
            if confidence >= self.CONFIDENCE_THRESHOLD or volume > 0.01:
                self.display_full_detection(
                    volume, smoothed_db, smoothed_distance, description,
                    predicted_class, confidence, class_icon, sound_type, sound_icon
                )
                self.detections_count += 1
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    
    def display_full_detection(self, volume, db_level, distance, description, 
                              predicted_class, confidence, class_icon, sound_type, sound_icon):
        """–ü–æ–ª–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        current_time = datetime.now().strftime("%H:%M:%S")
        distance_icon = self.get_distance_icon(distance)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        vol_bar, dist_bar, conf_bar = self.create_progress_bars(volume, distance, confidence)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        print(f"\n{class_icon} === –î–ï–¢–ï–ö–¶–ò–Ø #{self.detections_count} === {current_time}")
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        print(vol_bar)
        print(dist_bar)
        if conf_bar:
            print(conf_bar)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"\nü§ñ –ö–ª–∞—Å—Å:         {predicted_class.upper()}")
        print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:   {confidence:.2f} ({confidence*100:.1f}%)")
        print(f"üì¢ –î–µ—Ü–∏–±–µ–ª—ã:      {db_level:.1f} –¥–ë")
        print(f"üìè –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ:    {distance_icon} {self.format_distance(distance)}")
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ:      {description}")
        print(f"{sound_icon} –¢–∏–ø –∑–≤—É–∫–∞:     {sound_type.upper()}")
        print(f"üè† –û–∫—Ä—É–∂–µ–Ω–∏–µ:     {self.environment_type.upper()}")
        
        print("=" * 65)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.last_detection = {
            'class': predicted_class,
            'confidence': confidence,
            'distance': distance,
            'db_level': db_level,
            'sound_type': sound_type,
            'time': current_time
        }
    
    def list_audio_devices(self):
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤"""
        print("üé§ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
        devices = sd.query_devices()
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                print(f"   {i}: {device['name']} ‚úÖ")
    
    def start_detection(self):
        """–ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        print("\nüéØ === –ü–ê–†–ê–ú–ï–¢–†–´ –î–ï–¢–ï–ö–¢–û–†–ê ===")
        print(f"   üìä –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {self.SAMPLE_RATE} –ì—Ü")
        print(f"   üéöÔ∏è –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {self.CONFIDENCE_THRESHOLD}")
        print(f"   üîá –ü–æ—Ä–æ–≥ —à—É–º–∞: {self.NOISE_THRESHOLD}")
        print(f"   üéöÔ∏è –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å: {self.MIN_VOLUME}")
        print(f"   üè† –û–∫—Ä—É–∂–µ–Ω–∏–µ: {self.environment_type}")
        print(f"   ü§ñ AI –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {'‚úÖ' if self.classifier else '‚ùå'}")
        print("=" * 50)
        
        self.list_audio_devices()
        
        print("\nüéØ –ü–æ–ª–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        print("üó£Ô∏è –ì–æ–≤–æ—Ä–∏—Ç–µ –∏–ª–∏ –∏–∑–¥–∞–≤–∞–π—Ç–µ –∑–≤—É–∫–∏...")
        print("ü§ñ AI –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –∫–ª–∞—Å—Å –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ")
        print("(Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)\n")
        
        self.running = True
        
        try:
            with sd.InputStream(
                samplerate=self.SAMPLE_RATE,
                channels=1,
                callback=self.audio_callback,
                blocksize=self.CHUNK_SIZE,
                dtype=np.float32
            ):
                while self.running:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            print(f"\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞... (–≤—Å–µ–≥–æ –¥–µ—Ç–µ–∫—Ü–∏–π: {self.detections_count})")
            self.running = False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        finally:
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")

def main():
    try:
        detector = FullDistanceDetector()
        detector.start_detection()
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()