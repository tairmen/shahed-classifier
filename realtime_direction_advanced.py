import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import sounddevice as sd
import time
from collections import deque
import threading
import sys
import math
from scipy import signal
from scipy.signal import correlate

# –ü—É—Ç–∏
MODEL_PATH = "model/my_sound_model.h5"
yamnet_model = hub.load("https://tfhub.dev/google/yamnet/1")
classifier = tf.keras.models.load_model(MODEL_PATH)
class_names = ["negative", "positive"]

SAMPLE_RATE = 16000
BLOCK_DURATION = 0.5  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–∫–ª–∏–∫–∞
BLOCK_SIZE = int(SAMPLE_RATE * BLOCK_DURATION)
MIN_CONFIDENCE = 0.8
SMOOTH_WINDOW = 3
RMS_THRESHOLD = 0.008  # –ù–µ–º–Ω–æ–≥–æ —Å–Ω–∏–∑–∏–ª–∏ –ø–æ—Ä–æ–≥
CHANNELS = 2

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
SPEED_OF_SOUND = 343.0  # –º/—Å
MIC_DISTANCE = 0.15     # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞–º–∏ (15 —Å–º)

# –ë—É—Ñ–µ—Ä—ã
prediction_buffer = deque(maxlen=SMOOTH_WINDOW)
volume_buffer_left = deque(maxlen=30)
volume_buffer_right = deque(maxlen=30)
direction_buffer = deque(maxlen=15)
confidence_buffer = deque(maxlen=10)
last_prediction = None
last_time = 0
is_running = True

class AdvancedDirectionDetector:
    def __init__(self, sample_rate=16000, mic_distance=0.15):
        self.sample_rate = sample_rate
        self.mic_distance = mic_distance
        self.max_delay_samples = int((mic_distance / SPEED_OF_SOUND) * sample_rate)
        
    def enhance_signal(self, signal_data):
        """–£–ª—É—á—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–∏–∑–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —à—É–º–∞
        sos = signal.butter(4, 100, btype='high', fs=self.sample_rate, output='sos')
        filtered = signal.sosfilt(sos, signal_data)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if np.max(np.abs(filtered)) > 0:
            filtered = filtered / np.max(np.abs(filtered))
        
        return filtered
    
    def calculate_direction_advanced(self, left_channel, right_channel):
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        try:
            # –£–ª—É—á—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
            left_enhanced = self.enhance_signal(left_channel)
            right_enhanced = self.enhance_signal(right_channel)
            
            # –í–∑–∞–∏–º–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
            correlation = correlate(left_enhanced, right_enhanced, mode='full')
            
            # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º—É–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            lags = signal.correlation_lags(len(left_enhanced), len(right_enhanced), mode='full')
            max_corr_idx = np.argmax(correlation)
            delay_samples = lags[max_corr_idx]
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            delay_samples = np.clip(delay_samples, -self.max_delay_samples, self.max_delay_samples)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –≤—Ä–µ–º—è –∏ —É–≥–æ–ª
            delay_time = delay_samples / self.sample_rate
            
            if abs(delay_time) > 0:
                # –í—ã—á–∏—Å–ª—è–µ–º —É–≥–æ–ª –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ
                sin_theta = (delay_time * SPEED_OF_SOUND) / self.mic_distance
                sin_theta = np.clip(sin_theta, -1, 1)
                
                angle_rad = math.asin(sin_theta)
                angle_deg = math.degrees(angle_rad)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                correlation_quality = correlation[max_corr_idx] / np.max(correlation)
                
                return angle_deg, delay_time, correlation_quality
            else:
                return 0.0, 0.0, 0.0
                
        except Exception as e:
            return 0.0, 0.0, 0.0
    
    def calculate_phase_difference(self, left_channel, right_channel):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞–∑–Ω–æ—Å—Ç—å —Ñ–∞–∑ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # FFT –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–∑
            left_fft = np.fft.fft(left_channel)
            right_fft = np.fft.fft(right_channel)
            
            # –ù–∞—Ö–æ–¥–∏–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â—É—é —á–∞—Å—Ç–æ—Ç—É
            freqs = np.fft.fftfreq(len(left_channel), 1/self.sample_rate)
            left_magnitude = np.abs(left_fft)
            
            # –ë–µ—Ä–µ–º —á–∞—Å—Ç–æ—Ç—ã –æ—Ç 200 –¥–æ 2000 Hz (—Ä–µ—á–µ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω)
            freq_mask = (freqs > 200) & (freqs < 2000)
            if np.any(freq_mask):
                dominant_freq_idx = np.argmax(left_magnitude[freq_mask])
                actual_idx = np.where(freq_mask)[0][dominant_freq_idx]
                
                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å —Ñ–∞–∑
                phase_diff = np.angle(left_fft[actual_idx]) - np.angle(right_fft[actual_idx])
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —É–≥–æ–ª
                wavelength = SPEED_OF_SOUND / freqs[actual_idx]
                angle_rad = math.asin(np.clip((phase_diff * wavelength) / (2 * math.pi * self.mic_distance), -1, 1))
                angle_deg = math.degrees(angle_rad)
                
                return angle_deg, freqs[actual_idx]
            else:
                return 0.0, 0.0
                
        except Exception:
            return 0.0, 0.0

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
direction_detector = AdvancedDirectionDetector()

def extract_embedding_from_audio(audio):
    scores, embeddings, spectrogram = yamnet_model(audio)
    embedding = tf.reduce_mean(embeddings, axis=0)
    return embedding

def smooth_predictions(new_prediction):
    prediction_buffer.append(new_prediction)
    if len(prediction_buffer) < SMOOTH_WINDOW:
        return None
    
    negative_count = sum(1 for p in prediction_buffer if p == 0)
    positive_count = sum(1 for p in prediction_buffer if p == 1)
    return 0 if negative_count >= positive_count else 1

def get_direction_description_advanced(angle, quality=1.0):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞"""
    confidence_emoji = "üü¢" if quality > 0.7 else "üü°" if quality > 0.4 else "üî¥"
    
    if abs(angle) < 5:
        return "üìç –¢–û–ß–ù–û –¶–ï–ù–¢–†", "üéØ", confidence_emoji
    elif abs(angle) < 15:
        direction = "‚ÜôÔ∏è –õ–ï–í–ï–ï" if angle > 0 else "‚ÜòÔ∏è –ü–†–ê–í–ï–ï"
        return direction, "‚ÜôÔ∏è" if angle > 0 else "‚ÜòÔ∏è", confidence_emoji
    elif abs(angle) < 30:
        direction = "‚¨ÖÔ∏è –õ–ï–í–û-–¶–ï–ù–¢–†" if angle > 0 else "‚û°Ô∏è –ü–†–ê–í–û-–¶–ï–ù–¢–†"
        return direction, "‚¨ÖÔ∏è" if angle > 0 else "‚û°Ô∏è", confidence_emoji
    elif abs(angle) < 50:
        direction = "‚¨ÖÔ∏è –õ–ï–í–´–ô" if angle > 0 else "‚û°Ô∏è –ü–†–ê–í–´–ô"
        return direction, "‚¨ÖÔ∏è" if angle > 0 else "‚û°Ô∏è", confidence_emoji
    else:
        direction = "‚¨ÖÔ∏è –ö–†–ê–ô–ù–ï –õ–ï–í–´–ô" if angle > 0 else "‚û°Ô∏è –ö–†–ê–ô–ù–ï –ü–†–ê–í–´–ô"
        return direction, "‚¨ÖÔ∏è" if angle > 0 else "‚û°Ô∏è", confidence_emoji

def create_3d_direction_visualizer(angle, quality=1.0, width=40):
    """–°–æ–∑–¥–∞–µ—Ç 3D ASCII –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    # –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ–ª–æ—Å–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    center = width // 2
    pos = center + int((angle / 90) * (width // 2))
    pos = np.clip(pos, 0, width - 1)
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
    bar = list("‚ñë" * width)
    
    # –†–∞–∑–º—ã—Ç–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
    spread = max(1, int(3 * (1 - quality)))
    
    for i in range(max(0, pos - spread), min(width, pos + spread + 1)):
        if i == pos:
            bar[i] = "üîä" if quality > 0.7 else "üîâ" if quality > 0.4 else "üîà"
        else:
            bar[i] = "‚ñì" if quality > 0.7 else "‚ñí" if quality > 0.4 else "‚ñë"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫–∏
    bar[0] = "L"
    bar[center] = "|"
    bar[width - 1] = "R"
    
    return "".join(bar)

def create_polar_visualization(angle, distance_estimate=1.0):
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª—è—Ä–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ–ª–æ–∂–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    # –ü—Ä–æ—Å—Ç–∞—è ASCII –ø–æ–ª—è—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
    rows = 7
    cols = 15
    
    # –¶–µ–Ω—Ç—Ä –¥–∏–∞–≥—Ä–∞–º–º—ã
    center_row = rows // 2
    center_col = cols // 2
    
    # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    angle_rad = math.radians(angle)
    source_row = center_row - int(distance_estimate * 2 * math.sin(angle_rad))
    source_col = center_col + int(distance_estimate * 4 * math.cos(angle_rad))
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–∏–∞–≥—Ä–∞–º–º—ã
    source_row = np.clip(source_row, 0, rows - 1)
    source_col = np.clip(source_col, 0, cols - 1)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—É
    diagram = [["¬∑" for _ in range(cols)] for _ in range(rows)]
    
    # –¶–µ–Ω—Ç—Ä (–º–∏–∫—Ä–æ—Ñ–æ–Ω)
    diagram[center_row][center_col] = "üé§"
    
    # –ò—Å—Ç–æ—á–Ω–∏–∫ –∑–≤—É–∫–∞
    diagram[source_row][source_col] = "üîä"
    
    # –†–∞–º–∫–∞
    for i in range(rows):
        diagram[i][0] = diagram[i][cols-1] = "|"
    for j in range(cols):
        diagram[0][j] = diagram[rows-1][j] = "-"
    
    return "\n".join("".join(row) for row in diagram)

def advanced_stats_display():
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º"""
    while is_running:
        if direction_buffer and len(direction_buffer) >= 5:
            recent_data = list(direction_buffer)[-10:]
            avg_angle = np.mean(recent_data)
            angle_std = np.std(recent_data)
            
            # –û—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            stability = "üü¢ –°–¢–ê–ë–ò–õ–¨–ù–û" if angle_std < 10 else "üü° –£–ú–ï–†–ï–ù–ù–û" if angle_std < 20 else "üî¥ –ù–ï–°–¢–ê–ë–ò–õ–¨–ù–û"
            
            # –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            avg_quality = np.mean(confidence_buffer) if confidence_buffer else 0
            
            direction_desc, emoji, quality_emoji = get_direction_description_advanced(avg_angle, avg_quality)
            
            print(f"\nüß≠ === –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø ===")
            print(f"   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction_desc}")
            print(f"   –£–≥–æ–ª: {avg_angle:.1f}¬∞ ¬± {angle_std:.1f}¬∞")
            print(f"   –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {stability}")
            print(f"   –ö–∞—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–∞: {quality_emoji} {avg_quality:.2f}")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            direction_viz = create_3d_direction_visualizer(avg_angle, avg_quality)
            print(f"   –ü–æ–∑–∏—Ü–∏—è: {direction_viz}")
            
            # –ü–æ–ª—è—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
            if abs(avg_angle) > 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è —á–µ—Ç–∫–∏—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
                polar_viz = create_polar_visualization(avg_angle)
                print(f"   –ü–æ–ª—è—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞:")
                for line in polar_viz.split('\n'):
                    print(f"     {line}")
            
            print("=" * 60)
            
            for _ in range(3):
                print()
        
        time.sleep(5)

def audio_callback(indata, frames, time_info, status):
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º"""
    global last_prediction, last_time
    
    if status:
        print(f"\n‚ö†Ô∏è Audio status: {status}")
    
    try:
        # –†–∞–∑–¥–µ–ª—è–µ–º –∫–∞–Ω–∞–ª—ã
        if indata.shape[1] >= 2:
            left_channel = indata[:, 0].astype(np.float32)
            right_channel = indata[:, 1].astype(np.float32)
        else:
            mono = indata[:, 0].astype(np.float32)
            left_channel = right_channel = mono
        
        # –í—ã—á–∏—Å–ª—è–µ–º RMS
        left_rms = np.sqrt(np.mean(left_channel**2))
        right_rms = np.sqrt(np.mean(right_channel**2))
        avg_rms = (left_rms + right_rms) / 2
        
        volume_buffer_left.append(left_rms)
        volume_buffer_right.append(right_rms)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        if avg_rms > RMS_THRESHOLD:
            angle, delay, quality = direction_detector.calculate_direction_advanced(left_channel, right_channel)
            phase_angle, dominant_freq = direction_detector.calculate_phase_difference(left_channel, right_channel)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            combined_angle = (angle + phase_angle) / 2 if abs(phase_angle) < 90 else angle
            
            direction_buffer.append(combined_angle)
            confidence_buffer.append(quality)
        
        if avg_rms < RMS_THRESHOLD:
            return
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        mono_audio = (left_channel + right_channel) / 2
        emb = extract_embedding_from_audio(mono_audio)
        pred = classifier.predict(np.expand_dims(emb, axis=0), verbose=0)[0]
        label_idx = np.argmax(pred)
        confidence = pred[label_idx]
        
        smoothed_prediction = smooth_predictions(label_idx)
        
        current_time = time.time()
        if (smoothed_prediction is not None and 
            confidence > MIN_CONFIDENCE and 
            smoothed_prediction != last_prediction and
            current_time - last_time > 1.0):
            
            label = class_names[smoothed_prediction]
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
            if direction_buffer and confidence_buffer:
                current_angle = direction_buffer[-1]
                signal_quality = confidence_buffer[-1]
                direction_desc, emoji, quality_emoji = get_direction_description_advanced(current_angle, signal_quality)
            else:
                current_angle = 0
                signal_quality = 0
                direction_desc, emoji, quality_emoji = "üìç –ù–ï–ò–ó–í–ï–°–¢–ù–û", "‚ùì", "üî¥"
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            sys.stdout.write("\r" + " " * 120 + "\r")
            
            result_emoji = "üî¥" if label == "negative" else "üü¢"
            print(f"\n{result_emoji} === –ü–†–û–î–í–ò–ù–£–¢–û–ï –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï === {result_emoji}")
            print(f"üéß –ö–ª–∞—Å—Å:         {label.upper()}")
            print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:   {confidence:.2f} ({confidence*100:.1f}%)")
            print(f"üîä –ì—Ä–æ–º–∫–æ—Å—Ç—å:     L:{left_rms:.3f} R:{right_rms:.3f}")
            print(f"üß≠ –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:   {direction_desc}")
            print(f"üìê –£–≥–æ–ª:          {current_angle:.1f}¬∞")
            print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ:      {quality_emoji} {signal_quality:.2f}")
            print(f"‚è∞ –í—Ä–µ–º—è:         {time.strftime('%H:%M:%S')}")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            direction_viz = create_3d_direction_visualizer(current_angle, signal_quality)
            print(f"üìç –ü–æ–∑–∏—Ü–∏—è:       {direction_viz}")
            
            print("=" * 60)
            
            last_prediction = smoothed_prediction
            last_time = current_time
            
    except Exception as e:
        print(f"\n‚ùå Error in audio callback: {e}")

def main():
    print("üéôÔ∏è === –ü–†–û–î–í–ò–ù–£–¢–´–ô –î–ï–¢–ï–ö–¢–û–† –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø –ó–í–£–ö–ê ===")
    print("üß≠ –£–ª—É—á—à–µ–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    print("üî¨ –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ —Ä–∞–∑–Ω–æ—Å—Ç–∏ —Ñ–∞–∑")
    print("=" * 70)
    
    print(f"\nüîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"   –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞–º–∏: {MIC_DISTANCE*100} —Å–º")
    print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {(MIC_DISTANCE/SPEED_OF_SOUND)*1000:.2f} –º—Å")
    print(f"   –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ —É–≥–ª–∞: ~{math.degrees(math.asin(1/(SAMPLE_RATE*MIC_DISTANCE/SPEED_OF_SOUND))):.1f}¬∞")
    print("=" * 70)
    print("üéØ –ì–æ—Ç–æ–≤ –∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–º—É –∞–Ω–∞–ª–∏–∑—É –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è!")
    print("(Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)\n")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏
    stats_thread = threading.Thread(target=advanced_stats_display, daemon=True)
    stats_thread.start()
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫
    try:
        with sd.InputStream(channels=CHANNELS, samplerate=SAMPLE_RATE, 
                          callback=audio_callback, blocksize=BLOCK_SIZE):
            try:
                while True:
                    time.sleep(0.1)
            except KeyboardInterrupt:
                global is_running
                is_running = False
                print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ: {e}")

if __name__ == "__main__":
    main()