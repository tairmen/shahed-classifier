import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import sounddevice as sd
import time
from collections import deque
import threading
import sys

# –ü—É—Ç–∏
MODEL_PATH = "model/my_sound_model.h5"
yamnet_model = hub.load("https://tfhub.dev/google/yamnet/1")
classifier = tf.keras.models.load_model(MODEL_PATH)
class_names = ["negative", "positive"]

SAMPLE_RATE = 16000
BLOCK_DURATION = 1.0
BLOCK_SIZE = int(SAMPLE_RATE * BLOCK_DURATION)
MIN_CONFIDENCE = 0.8
SMOOTH_WINDOW = 3
RMS_THRESHOLD = 0.01

# –ë—É—Ñ–µ—Ä—ã –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
prediction_buffer = deque(maxlen=SMOOTH_WINDOW)
volume_buffer = deque(maxlen=20)
last_prediction = None
last_time = 0
is_running = True

def extract_embedding_from_audio(audio):
    scores, embeddings, spectrogram = yamnet_model(audio)
    embedding = tf.reduce_mean(embeddings, axis=0)
    return embedding

def smooth_predictions(new_prediction):
    prediction_buffer.append(new_prediction)
    if len(prediction_buffer) < SMOOTH_WINDOW:
        return None
    
    negative_count = sum(1 for p in prediction_buffer if p == 0)
    positive_count = sum(1 for p in prediction_buffer if p == 1)
    return 0 if negative_count >= positive_count else 1

def create_ascii_meter(volume, width=40):
    """–°–æ–∑–¥–∞–µ—Ç ASCII –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≥—Ä–æ–º–∫–æ—Å—Ç–∏"""
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if volume <= 0:
        normalized = 0
    else:
        normalized = min(1.0, np.log10(volume * 1000 + 1) / 3)
    
    filled = int(normalized * width)
    bar = "‚ñà" * filled + "‚ñë" * (width - filled)
    
    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç—É—Å–∞
    if volume < RMS_THRESHOLD:
        status = "üîá –¢–ò–•–û  "
    elif volume < 0.03:
        status = "üîâ –°–†–ï–î–ù–ï"
    else:
        status = "üîä –ì–†–û–ú–ö–û"
    
    # –ß–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    return f"{status} |{bar}| {volume:.3f}"

def create_frequency_bars(audio_data, n_bars=20):
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é —á–∞—Å—Ç–æ—Ç–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é"""
    if len(audio_data) < 512:
        return "üéµ " + "‚ñë" * n_bars
    
    # FFT –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–æ—Ç
    fft = np.abs(np.fft.fft(audio_data[-512:]))[:256]
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —á–∞—Å—Ç–æ—Ç—ã –≤ –ø–æ–ª–æ—Å—ã
    band_size = len(fft) // n_bars
    bands = []
    
    for i in range(n_bars):
        start = i * band_size
        end = start + band_size
        band_power = np.mean(fft[start:end])
        bands.append(band_power)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    max_power = max(bands) if max(bands) > 0 else 1
    bars = ""
    
    for power in bands:
        normalized = power / max_power
        if normalized > 0.8:
            bars += "‚ñà"
        elif normalized > 0.6:
            bars += "‚ñì"
        elif normalized > 0.4:
            bars += "‚ñí"
        elif normalized > 0.2:
            bars += "‚ñë"
        else:
            bars += " "
    
    return f"üéµ |{bars}|"

def display_stats():
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ real-time"""
    stats_history = deque(maxlen=60)  # –ò—Å—Ç–æ—Ä–∏—è –∑–∞ –º–∏–Ω—É—Ç—É
    
    while is_running:
        if volume_buffer:
            current_vol = volume_buffer[-1]
            avg_vol = np.mean(list(volume_buffer))
            max_vol = max(volume_buffer)
            
            stats_history.append(current_vol)
            
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏-–≥—Ä–∞—Ñ–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            if len(stats_history) >= 10:
                mini_graph = ""
                normalized_history = [v / (max(stats_history) or 1) for v in list(stats_history)[-20:]]
                for val in normalized_history:
                    if val > 0.8:
                        mini_graph += "‚ñÇ"
                    elif val > 0.6:
                        mini_graph += "‚ñÅ"
                    elif val > 0.4:
                        mini_graph += "‚ñÅ"
                    else:
                        mini_graph += "_"
            else:
                mini_graph = "_" * 20
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            print(f"\nüìä === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–£–î–ò–û ===")
            print(f"   –¢–µ–∫—É—â–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å: {current_vol:.4f}")
            print(f"   –°—Ä–µ–¥–Ω—è—è –≥—Ä–æ–º–∫–æ—Å—Ç—å:  {avg_vol:.4f}")
            print(f"   –ú–∞–∫—Å–∏–º—É–º:          {max_vol:.4f}")
            print(f"   –ò—Å—Ç–æ—Ä–∏—è: {mini_graph}")
            print(f"   –ü–æ—Ä–æ–≥ —à—É–º–∞:        {RMS_THRESHOLD:.4f}")
            print(f"   –°—Ç–∞—Ç—É—Å: {'üü¢ –ê–ö–¢–ò–í–ï–ù' if current_vol > RMS_THRESHOLD else 'üî¥ –¢–ò–®–ò–ù–ê'}")
            
            # –û—á–∏—â–∞–µ–º —ç–∫—Ä–∞–Ω —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è
            for _ in range(8):
                print()
        
        time.sleep(3)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã

def volume_display_thread():
    """–ü–æ—Ç–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏"""
    current_audio = deque(maxlen=1024)
    
    while is_running:
        if volume_buffer:
            current_vol = volume_buffer[-1]
            
            # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            volume_meter = create_ascii_meter(current_vol)
            
            # –ß–∞—Å—Ç–æ—Ç–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ)
            if len(current_audio) > 100:
                freq_bars = create_frequency_bars(list(current_audio))
            else:
                freq_bars = "üéµ " + "‚ñë" * 20
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            sys.stdout.write(f"\r{volume_meter}")
            sys.stdout.flush()
            
            # –ò–Ω–æ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            if int(time.time()) % 5 == 0:
                sys.stdout.write(f"\r{freq_bars}")
                sys.stdout.flush()
                time.sleep(0.5)
        
        time.sleep(0.1)

def audio_callback(indata, frames, time_info, status):
    global last_prediction, last_time
    
    if status:
        print(f"\n‚ö†Ô∏è Audio status: {status}")
    
    try:
        mono = np.mean(indata, axis=1).astype(np.float32)
        rms = np.sqrt(np.mean(mono**2))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä—ã
        volume_buffer.append(rms)
        
        if rms < RMS_THRESHOLD:
            return
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        emb = extract_embedding_from_audio(mono)
        pred = classifier.predict(np.expand_dims(emb, axis=0), verbose=0)[0]
        label_idx = np.argmax(pred)
        confidence = pred[label_idx]
        
        smoothed_prediction = smooth_predictions(label_idx)
        
        current_time = time.time()
        if (smoothed_prediction is not None and 
            confidence > MIN_CONFIDENCE and 
            smoothed_prediction != last_prediction and
            current_time - last_time > 1.0):
            
            label = class_names[smoothed_prediction]
            
            # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ –≤—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            sys.stdout.write("\r" + " " * 80 + "\r")
            
            # –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            emoji = "üî¥" if label == "negative" else "üü¢"
            print(f"\n{emoji} === –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï === {emoji}")
            print(f"üéß –ö–ª–∞—Å—Å:       {label.upper()}")
            print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f} ({confidence*100:.1f}%)")
            print(f"üîä –ì—Ä–æ–º–∫–æ—Å—Ç—å:   {rms:.3f}")
            print(f"‚è∞ –í—Ä–µ–º—è:       {time.strftime('%H:%M:%S')}")
            print("=" * 40)
            
            last_prediction = smoothed_prediction
            last_time = current_time
            
    except Exception as e:
        print(f"\n‚ùå Error in audio callback: {e}")

def main():
    print("üéôÔ∏è === –ü–†–û–î–í–ò–ù–£–¢–´–ô REAL-TIME –î–ï–¢–ï–ö–¢–û–† ===")
    print(f"üìä –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {MIN_CONFIDENCE}")
    print(f"üîÑ –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ: {SMOOTH_WINDOW} –∫–∞–¥—Ä–æ–≤")
    print(f"üéöÔ∏è –ü–æ—Ä–æ–≥ —à—É–º–∞: {RMS_THRESHOLD}")
    print(f"üéµ –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {SAMPLE_RATE} Hz")
    print("üìà –í–∫–ª—é—á–µ–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –∏ —á–∞—Å—Ç–æ—Ç")
    print("=" * 50)
    print("üéØ –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –ì–æ–≤–æ—Ä–∏—Ç–µ –∏–ª–∏ –∏–∑–¥–∞–≤–∞–π—Ç–µ –∑–≤—É–∫–∏...")
    print("(Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)\n")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    volume_thread = threading.Thread(target=volume_display_thread, daemon=True)
    volume_thread.start()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats_thread = threading.Thread(target=display_stats, daemon=True)
    stats_thread.start()
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫
    with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, 
                      callback=audio_callback, blocksize=BLOCK_SIZE):
        try:
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            global is_running
            is_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")

if __name__ == "__main__":
    main()